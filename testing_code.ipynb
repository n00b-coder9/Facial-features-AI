{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "blocked-mechanism",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "trying-witch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import fastai\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.vision.all import *\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "present-shore",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('./data/faces')\n",
    "output_path = './data/testing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "korean-lighting",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'../../datasets/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "criminal-survival",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = ImageDataLoaders.from_df(df, path, label_delim=' ',\n",
    "                               item_tfms=Resize(460), batch_tfms=aug_transforms(size=224),num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "color-withdrawal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.learner.Learner at 0x2a010f42448>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading our model\n",
    "learn = cnn_learner(dls, models.resnet50, pretrained=False)\n",
    "learn.load(\"ff_stage-2-rn50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "existing-september",
   "metadata": {},
   "outputs": [],
   "source": [
    " face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "tested-projector",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d65e609ad9f4491987ec2b2fd2027a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['black', 'has_thick_hair', 'no_freakles', 'no_glasses', 'no_wrinkles']\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['black', 'has_thick_hair', 'no_freakles', 'no_glasses', 'no_wrinkles']\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['black', 'has_thick_hair', 'no_freakles', 'no_glasses', 'no_wrinkles']\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['has_few_hairs', 'no_freakles', 'no_glasses', 'no_wrinkles', 'white']\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['black', 'has_thick_hair', 'no_freakles', 'no_glasses', 'no_wrinkles']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import imutils\n",
    "from tqdm.notebook import tqdm\n",
    "from fastai.vision import *\n",
    "itemlist = glob.glob('./data/testing/*.jpg')\n",
    "fc = face_cascade\n",
    "outputs = []\n",
    "wrinkles = [\"no_wrinkles\",\"wrinkles\"]\n",
    "freakles = [\"no_freakles\",\"freakles\"]\n",
    "glasses = [\"no_glasses\",\"normal_glasses\",\"sunglasses\"]\n",
    "hair_color = [\"brown\",\"black\",\"gray\",\"blond\",\"red\",\"white\",\"mixed\",\"other\"]\n",
    "top = [\"bald_or_shaved\",\"has_few_hairs\",\"has_thick_hair\",\" \"]\n",
    "for item in tqdm(itemlist):\n",
    "     ## Importing image using open cv\n",
    "    img = cv2.imread(item)\n",
    "    ## Resizing to constant width\n",
    "    img = imutils.resize(img, width=200)\n",
    "    \n",
    "    ## Finding actual size of image\n",
    "    H,W,_ = img.shape\n",
    "    \n",
    "    ## Converting BGR to RGB\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    ## Detecting faces on the image\n",
    "    face_coord = fc.detectMultiScale(gray,1.2,10,minSize=(50,50))\n",
    "    \n",
    "    ## If only one face is found\n",
    "    if len(face_coord) == 1:\n",
    "        X, Y, w, h = face_coord[0]\n",
    "    \n",
    "    ## If no face found --> SKIP\n",
    "    elif len(face_coord)==0:\n",
    "        continue\n",
    "    \n",
    "    ## If multiple faces are found take the one with largest area\n",
    "    else:\n",
    "        max_val = 0\n",
    "        max_idx = 0\n",
    "        for idx in range(len(face_coord)):\n",
    "            _, _, w_i, h_i = face_coord[idx]\n",
    "            if w_i*h_i > max_val:\n",
    "                max_idx = idx\n",
    "                max_val = w_i*h_i\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            X, Y, w, h = face_coord[max_idx]\n",
    "    \n",
    "    ## Crop and export the image\n",
    "    img_cp = img[\n",
    "            max(0,Y - int(0.35*h)): min(Y + int(1.35*h), H),\n",
    "            max(0,X - int(w*0.35)): min(X + int(1.35*w), W)\n",
    "        ].copy()\n",
    "    ## Prediction of facial featues\n",
    "    temp = []\n",
    "    img_fastai = torch.from_numpy(np.array(img_cp,copy = False))\n",
    "    prediction = str(\n",
    "        learn.predict(img_fastai)[0]\n",
    "    ).split(\";\")[0]\n",
    "    cnt = 0\n",
    "    #print(item)\n",
    "    temp.append(item.split('\\\\')[1])\n",
    "    for item in wrinkles:\n",
    "        if item in prediction:\n",
    "            temp.append(cnt)\n",
    "            break\n",
    "        cnt+=1\n",
    "    cnt = 0\n",
    "    for item in freakles:\n",
    "        if item in prediction:\n",
    "            temp.append(cnt)\n",
    "            break\n",
    "        cnt+=1\n",
    "    cnt = 0\n",
    "    for item in glasses:\n",
    "        if item in prediction:\n",
    "            temp.append(cnt)\n",
    "            break\n",
    "        cnt+=1\n",
    "    cnt = 0\n",
    "    for item in hair_color:\n",
    "        if item in prediction:\n",
    "            temp.append(cnt)\n",
    "            break\n",
    "        cnt+=1\n",
    "    cnt = 0\n",
    "    for item in top:\n",
    "        if item in prediction:\n",
    "            temp.append(cnt)\n",
    "            break\n",
    "        cnt+=1\n",
    "    outputs.append(temp)\n",
    "    print(prediction)\n",
    "headers = [\"image_name\",\"wrinkles\",\"freakles\",\"glasses\",\"hair_color\",\"hair_top\"]\n",
    "pd.DataFrame(outputs).to_csv(\"output.csv\",header = headers , index = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
